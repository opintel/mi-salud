{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from sklearn.externals import joblib\n",
    "import re\n",
    "import script_reglas\n",
    "import unicodedata\n",
    "from numpy import reshape, concatenate, unique, vectorize, array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_stem_tfidf=joblib.load('./modelo/mat_tfidf.pkl') #1\n",
    "pca=joblib.load('./modelo/pca.pkl')  #2\n",
    "clasificador=joblib.load('./modelo/modelo.pkl') # 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesa_texto(texto):\n",
    "    texto=texto.lower()\n",
    "    texto=re.sub('^[ \\t]+|[ \\t]+$', '', texto) \n",
    "\n",
    "    texto=re.sub('[^\\w\\s]','', texto)\n",
    "\n",
    "    texto=script_reglas.give_emoji_free_text(texto)\n",
    "\n",
    "    texto=unicodedata.normalize('NFD', texto).encode('ascii', 'ignore').decode('utf-8')\n",
    "    wc=len(str(texto).split(\" \"))\n",
    "    texto=re.sub('ola|\\n|buena noche|buenos dias|buenos dia|buen dia|buenas noches|buenas tardes|buenas tarde|buen dia|bien dia|buena tardes|buena tarde|saludos|hola','', texto)\n",
    "    texto=re.sub('^[ \\t]+|[ \\t]+$', '', texto)\n",
    "    return texto , wc\n",
    "\n",
    "\n",
    "def tokenize_and_stem(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems\n",
    "\n",
    "def predice_modelo(contact_uuid, texto, token):\n",
    "    response = requests.get(\"http://rapidpro.datos.gob.mx/api/v2/runs.json\",\n",
    "                            headers={\"Authorization\": token},\n",
    "                            params={\"contact\": contact_uuid})\n",
    "    response=json.loads(response.text)\n",
    "    hora=response['results'][0]['created_on']\n",
    "    hora=int(hora[11:13])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    texto, wc =procesa_texto(texto)\n",
    "\n",
    "    wc=reshape(wc, (-1, 1))\n",
    "    hora=reshape(hora, (-1, 1))\n",
    "\n",
    "\n",
    "    tfidf=features_stem_tfidf.transform([texto])\n",
    "    features=pca.transform(tfidf)\n",
    "\n",
    "    features=concatenate((features, wc), axis=1)\n",
    "    features=concatenate((features, hora), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "    proba=clasificador.predict_proba(features)\n",
    "\n",
    "\n",
    "    conc=proba*100\n",
    "    conc=conc*conc\n",
    "    conc=conc.sum()\n",
    "\n",
    "\n",
    "\n",
    "    proba_orig=proba\n",
    "    proba=proba/counts\n",
    "\n",
    "\n",
    "    pred=proba.argmax()\n",
    "    max_proba=proba_orig.max()\n",
    "    \n",
    "\n",
    "    \n",
    "    pred=str(vectorize(label_map.get)(pred))\n",
    "    \n",
    "    \n",
    "    if conc<minimo_conc:\n",
    "        pred='No_se_puede_asignar_etiqueta'\n",
    "        \n",
    "    out={'pred':pred,\n",
    "        'probabilidad_maxima':max_proba,\n",
    "        'indice_seguridad':conc}\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Proporción por etiqueta (NO CAMBIAR)\n",
    "counts=[0.00616016,  0.04928131,\n",
    "        0.00718686,  0.28644764,\n",
    "        0.14887064,0.34599589,\n",
    "        0.05954825,  0.01848049,\n",
    "        0.07802875]\n",
    "\n",
    "##THRESHOLD DE CONCENTRACIÓN. ABAJO DE ESTO NO SE PUEDE PREDECIR\n",
    "\n",
    "minimo_conc=4106.366777\n",
    "\n",
    "##ETIQUETAS DE PREDICCIONES (NO CAMBIAR)\n",
    "label_map={0:'otra',\n",
    "          1:'informacion',\n",
    "          2: 'nacimiento',\n",
    "          3: 'respuesta',\n",
    "          4: 'emergencia',\n",
    "          5: 'pregunta',\n",
    "          6: 'pregunta',\n",
    "          7: 'otra_queja',\n",
    "          8: 'pregunta'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'indice_seguridad': 6038.9995,\n",
       " 'pred': 'nacimiento',\n",
       " 'probabilidad_maxima': 0.76466596}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ID CONTACTO\n",
    "contact_uuid='fb82e199-ac49-41cd-a269-1654f29e180b'\n",
    "#TEXTO DEL MENSAJE\n",
    "texto='mi bebe ya nacio'\n",
    "# TOKEN DEL API\n",
    "token=\"Token [llenar aqui]\"\n",
    "\n",
    "predice_modelo(contact_uuid, texto, token)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook funcion_modelo.ipynb to script\n",
      "[NbConvertApp] Writing 3372 bytes to funcion_modelo.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script funcion_modelo.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
